#!/usr/bin/env python3
"""
filter_404_expired.py - Custom Filter for 404 Errors and Expired Domains

‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå CSV ‡∏ó‡∏µ‡πà export ‡πÅ‡∏•‡πâ‡∏ß ‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡πÄ‡∏â‡∏û‡∏≤‡∏∞:
- HTTP 404 errors
- ‡πÇ‡∏î‡πÄ‡∏°‡∏ô‡∏´‡∏°‡∏î‡∏≠‡∏≤‡∏¢‡∏∏ (NO_DNS, DEAD_DOMAIN)
- SSL errors (‡∏≠‡∏≤‡∏à‡πÄ‡∏õ‡πá‡∏ô‡πÇ‡∏î‡πÄ‡∏°‡∏ô‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤)

Usage:
    python filter_404_expired.py input.csv output.csv
"""

import pandas as pd
import argparse
import sys
from pathlib import Path


def filter_dead_websites(input_csv: str, output_csv: str = None) -> str:
    """
    ‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ 404 error ‡∏´‡∏£‡∏∑‡∏≠‡πÇ‡∏î‡πÄ‡∏°‡∏ô‡∏´‡∏°‡∏î‡∏≠‡∏≤‡∏¢‡∏∏
    
    Args:
        input_csv: Path ‡πÑ‡∏ü‡∏•‡πå CSV input
        output_csv: Path ‡πÑ‡∏ü‡∏•‡πå CSV output (‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏î‡∏¥‡∏°‡πÅ‡∏ï‡πà‡πÄ‡∏û‡∏¥‡πà‡∏° _filtered)
    
    Returns:
        Path ‡πÑ‡∏ü‡∏•‡πå output
    """
    # ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå CSV
    try:
        df = pd.read_csv(input_csv)
        print(f"üìä ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏î‡πâ {len(df)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
    except Exception as e:
        print(f"‚ùå Error reading CSV file: {e}")
        return ""
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö columns ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
    required_columns = ['website_status', 'website_url']
    missing_columns = [col for col in required_columns if col not in df.columns]
    
    if missing_columns:
        print(f"‚ùå Missing columns: {missing_columns}")
        print(f"Available columns: {list(df.columns)}")
        return ""
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
    print(f"\nüìà ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô:")
    status_counts = df['website_status'].value_counts()
    for status, count in status_counts.items():
        print(f"   {status}: {count} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
    
    # ‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
    target_statuses = {
        'HTTP_ERROR_4XX',    # ‡∏£‡∏ß‡∏° 404 errors
        'NO_DNS',            # ‡πÇ‡∏î‡πÄ‡∏°‡∏ô‡∏´‡∏°‡∏î‡∏≠‡∏≤‡∏¢‡∏∏/‡πÑ‡∏°‡πà‡∏û‡∏ö DNS
        'DEAD_DOMAIN',       # ‡πÇ‡∏î‡πÄ‡∏°‡∏ô‡∏ï‡∏≤‡∏¢
        'SSL_ERROR',         # SSL ‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ (‡∏≠‡∏≤‡∏à‡πÄ‡∏õ‡πá‡∏ô‡πÇ‡∏î‡πÄ‡∏°‡∏ô‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤)
    }
    
    # Filter data
    filtered_df = df[df['website_status'].isin(target_statuses)].copy()
    
    # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏ï‡∏≤‡∏° website_status ‡πÅ‡∏•‡∏∞ rating
    filtered_df = filtered_df.sort_values(['website_status', 'rating'], ascending=[True, False])
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå output ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏£‡∏∞‡∏ö‡∏∏
    if output_csv is None:
        input_path = Path(input_csv)
        output_csv = str(input_path.parent / f"{input_path.stem}_404_expired{input_path.suffix}")
    
    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå
    try:
        filtered_df.to_csv(output_csv, index=False, encoding='utf-8-sig')
        print(f"\n‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {output_csv}")
        print(f"üìä ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏Å‡∏£‡∏≠‡∏á‡πÅ‡∏•‡πâ‡∏ß: {len(filtered_df)} ‡∏à‡∏≤‡∏Å {len(df)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
    except Exception as e:
        print(f"‚ùå Error saving CSV file: {e}")
        return ""
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏´‡∏•‡∏±‡∏á‡∏Å‡∏£‡∏≠‡∏á
    if len(filtered_df) > 0:
        print(f"\nüìà ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏´‡∏•‡∏±‡∏á‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏≠‡∏á:")
        filtered_status_counts = filtered_df['website_status'].value_counts()
        for status, count in filtered_status_counts.items():
            print(f"   {status}: {count} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
        
        print(f"\nüéØ ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå‡∏ó‡∏µ‡πà‡∏Å‡∏£‡∏≠‡∏á‡πÑ‡∏î‡πâ:")
        sample_size = min(5, len(filtered_df))
        for i, (_, row) in enumerate(filtered_df.head(sample_size).iterrows(), 1):
            print(f"   {i}. {row.get('business_name', 'N/A')} - {row['website_url']} ({row['website_status']})")
    else:
        print(f"\n‚ö†Ô∏è  ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏ï‡∏≤‡∏°‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç")
    
    return output_csv


def main():
    parser = argparse.ArgumentParser(
        description="‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ 404 error ‡∏´‡∏£‡∏∑‡∏≠‡πÇ‡∏î‡πÄ‡∏°‡∏ô‡∏´‡∏°‡∏î‡∏≠‡∏≤‡∏¢‡∏∏",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
    # ‡∏Å‡∏£‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡∏°‡πà
    python filter_404_expired.py output/dead_websites_Bangkok_20241210.csv
    
    # ‡∏Å‡∏£‡∏≠‡∏á‡πÅ‡∏•‡∏∞‡∏£‡∏∞‡∏ö‡∏∏‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå output ‡πÄ‡∏≠‡∏á
    python filter_404_expired.py input.csv filtered_output.csv
        """
    )
    
    parser.add_argument(
        "input_csv",
        help="Path ‡πÑ‡∏ü‡∏•‡πå CSV input ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏≠‡∏á"
    )
    parser.add_argument(
        "output_csv",
        nargs="?",
        help="Path ‡πÑ‡∏ü‡∏•‡πå CSV output (optional, ‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏î‡∏¥‡∏°‡πÅ‡∏ï‡πà‡πÄ‡∏û‡∏¥‡πà‡∏° _404_expired)"
    )
    
    args = parser.parse_args()
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÑ‡∏ü‡∏•‡πå input ‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏à‡∏£‡∏¥‡∏á
    if not Path(args.input_csv).exists():
        print(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå: {args.input_csv}")
        sys.exit(1)
    
    # ‡∏£‡∏±‡∏ô filter
    result = filter_dead_websites(args.input_csv, args.output_csv)
    
    if result:
        print(f"\nüéâ ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô! ‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏Å‡∏£‡∏≠‡∏á‡πÅ‡∏•‡πâ‡∏ß‡∏≠‡∏¢‡∏π‡πà‡∏ó‡∏µ‡πà: {result}")
    else:
        print(f"\n‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
        sys.exit(1)


if __name__ == "__main__":
    main()
